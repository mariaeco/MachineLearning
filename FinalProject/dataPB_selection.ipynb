{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0cbc85-a56d-4073-88e5-d744fea0ba02",
   "metadata": {},
   "source": [
    "# üìö SELE√á√ÉO DE MICRODADOS DO ENEM\n",
    "\n",
    "### OS MICRODADOS POR ANO EST√ÉO DISPON√çVEIS AQUI:\n",
    "\n",
    "https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem\n",
    "\n",
    "Baixe cada ano e coloque na pasta Data/ em seu projeto.\n",
    "\n",
    "Ap√≥s isso √© s√≥ executar o c√≥digo abaixo, que ir√£o filtrar o Estado da Para√≠ba, as vari√°veis de interesse, salvar cada ano em um .csv, e ao final √© feito um merge, para juntar todos em um √∫nico documento.\n",
    "\n",
    "OBS: Caso n√£o tenha espa√ßo suficiente no computador fa√ßa o procedimento de poucos em poucos anos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f1ce52-440e-4423-a334-c2cefac8bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b67b84-07ff-44fe-9faf-7c30bbf7da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMEIRO DEVEMOS CHECAR OS ARQUIVOS QUE CADA ZIP CONT√âM, POIS OS NOMES DE PASTAS E ARQUIVOS N√ÉO EST√ÉO PADRONIZADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df897666-42ea-4705-9ca4-6d63cf69b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DADOS/\n",
      "DADOS/ITENS_PROVA_2009.csv\n",
      "DADOS/MICRODADOS_ENEM_2009.csv\n",
      "DICION‚ï°RIO/\n",
      "DICION‚ï°RIO/Dicion√°rio_Microdados_ENEM_2009.ods\n",
      "DICION‚ï°RIO/Dicion√°rio_Microdados_ENEM_2009.xlsx\n",
      "DICION‚ï°RIO/~$Dicion√°rio_Microdados_ENEM_2009.xlsx\n",
      "INPUTS/\n",
      "INPUTS/INPUT_R_ITENS_PROVA_2009.R\n",
      "INPUTS/INPUT_R_MICRODADOS_ENEM_2009.R\n",
      "INPUTS/INPUT_SAS_ITENS_PROVA_2009.sas\n",
      "INPUTS/INPUT_SAS_MICRODADOS_ENEM_2009.sas\n",
      "INPUTS/INPUT_SPSS_ITENS_PROVA_2009.sps\n",
      "INPUTS/INPUT_SPSS_MICRODADOS_ENEM_2009.sps\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/Edital_Enem_2009.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/enem_procedimentos_de_analise.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/entenda_a_sua_nota_no_enem_guia_do_participante.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/LEIA_ME_ENEM_2009.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/Manual_do_inscrito_enem2009.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/QUESTION‚ï°RIO SOCIOECONŒìMICO ENEM 2009.pdf\n",
      "LEIA-ME E DOCUMENTOS T√âCNICOS/Relatorio_pedagogico_enem_2009.pdf\n",
      "PROVAS E GABARITOS/\n",
      "PROVAS E GABARITOS/ENEM_2009_GAB_DIA_1.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_GAB_DIA_2.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_1_AMARELO_2.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_1_AZUL_1.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_1_BRANCO_3.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_1_ROSA_4.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_2_AMARELO_5.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_2_AZUL_7.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_2_CINZA_6.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_2_CINZA_LEDOR_6.pdf\n",
      "PROVAS E GABARITOS/ENEM_2009_PROVA_DIA_2_ROSA_8.pdf\n"
     ]
    }
   ],
   "source": [
    "with zipfile.ZipFile('Data/microdados_enem_2009.zip') as z:\n",
    "    #selecionando aqui apenas a planilha dos dados (no arquivo existem as provas, dicionarios, documentos tecnicos, para n√≥s s√≥ importam os dados\n",
    "    print(*z.namelist(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e29199-146e-4d45-a945-fe330ed9ab5e",
   "metadata": {},
   "source": [
    "### Vendo vari√°veis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc18fa3-7a17-4489-8aea-40fa8b4fb2db",
   "metadata": {},
   "source": [
    "## SALVANDO APENAS AS VARI√ÅVEIS DE INTERESSE E SELECIONANDO O ESTADO DA PARA√çBA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eede14c-fe0a-40ba-91b0-318d1b01e7d0",
   "metadata": {},
   "source": [
    "Anos de 2019-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d975865c-a694-45cd-ad9a-f405176b510d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_17028\\559312076.py:35: DtypeWarning: Columns (10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  enem_PB = pd.concat(chunk.query('SG_UF_ESC == \"PB\"') for chunk in chunks)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_17028\\559312076.py:35: DtypeWarning: Columns (10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  enem_PB = pd.concat(chunk.query('SG_UF_ESC == \"PB\"') for chunk in chunks)\n",
      "C:\\Users\\maria\\AppData\\Local\\Temp\\ipykernel_17028\\559312076.py:35: DtypeWarning: Columns (10,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  enem_PB = pd.concat(chunk.query('SG_UF_ESC == \"PB\"') for chunk in chunks)\n"
     ]
    }
   ],
   "source": [
    "year_list = [str(year) for year in range(2003, 2024)]\n",
    "\n",
    "ALL_columns = [\n",
    "    'NU_INSCRICAO','NU_ANO','TP_FAIXA_ETARIA','TP_SEXO','TP_ESTADO_CIVIL','TP_COR_RACA','TP_NACIONALIDADE',\n",
    "    'TP_ST_CONCLUSAO','TP_ANO_CONCLUIU','TP_ESCOLA','TP_ENSINO','IN_TREINEIRO','CO_MUNICIPIO_ESC','NO_MUNICIPIO_ESC',\n",
    "    'CO_UF_ESC','SG_UF_ESC','TP_DEPENDENCIA_ADM_ESC','TP_LOCALIZACAO_ESC','TP_SIT_FUNC_ESC','CO_MUNICIPIO_PROVA',\n",
    "    'NO_MUNICIPIO_PROVA','CO_UF_PROVA','SG_UF_PROVA','TP_PRESENCA_CN','TP_PRESENCA_CH','TP_PRESENCA_LC',\n",
    "    'TP_PRESENCA_MT','CO_PROVA_CN','CO_PROVA_CH','CO_PROVA_LC','CO_PROVA_MT','NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC',\n",
    "    'NU_NOTA_MT','TX_RESPOSTAS_CN','TX_RESPOSTAS_CH','TX_RESPOSTAS_LC','TX_RESPOSTAS_MT','TP_LINGUA','TX_GABARITO_CN',\n",
    "    'TX_GABARITO_CH','TX_GABARITO_LC','TX_GABARITO_MT','TP_STATUS_REDACAO','NU_NOTA_COMP1','NU_NOTA_COMP2',\n",
    "    'NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_REDACAO',\n",
    "    'Q001','Q002','Q003','Q004','Q005',\n",
    "    'Q006','Q007','Q008','Q009','Q010',\n",
    "    'Q011','Q012','Q013','Q014','Q015',\n",
    "    'Q016','Q017','Q018','Q019','Q020',\n",
    "    'Q021','Q022','Q023','Q024','Q025']\n",
    "\n",
    "for year in year_list:\n",
    "    if year == '2016':\n",
    "        filepath = f'DADOS/microdados_enem_{year}.csv'\n",
    "    if year == '2004':\n",
    "        filepath = f'Dados/MICRODADOS_ENEM_{year}.csv'\n",
    "    else:\n",
    "        filepath = f'DADOS/MICRODADOS_ENEM_{year}.csv'\n",
    "    with zipfile.ZipFile(f'Data/microdados_enem_{year}.zip') as z:\n",
    "        with z.open(filepath) as f:\n",
    "            chunks = pd.read_csv(f, \n",
    "                                 sep=';', \n",
    "                                 encoding='latin-1', \n",
    "                                 # usecols=ALL_columns, \n",
    "                                 chunksize=10000)  # l√™ de 100 mil em 100 mil linhas\n",
    "            \n",
    "            enem_PB = pd.concat(chunk.query('SG_UF_ESC == \"PB\"') for chunk in chunks)\n",
    "            \n",
    "    enem_PB.to_csv(f'Data/enem_{year}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e7746-9d93-4e0e-969f-d1a8cf0db475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
